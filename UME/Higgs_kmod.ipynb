{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/math/home/eruisun/software/anaconda/envs/LFI/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from utils import *\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    " \n",
    "# Define the network structure\n",
    "H = 300\n",
    "out = 100\n",
    "L = 1\n",
    "class DN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DN, self).__init__()\n",
    "        self.restored = False\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, out, bias=True),\n",
    "            #torch.nn.Dropout(p=0.5),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.model(input)\n",
    "        return output\n",
    "\n",
    "class another_DN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(another_DN, self).__init__()\n",
    "        self.restored = False\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, 28, bias=True),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        return output\n",
    "\n",
    "from kmod.kernel import DifferentiableKernel, KSTKernel, LinearKSTKernel\n",
    "from utils import Pdist2\n",
    "#class NeuralKernel(DifferentiableKernel, KSTKernel, LinearKSTKernel): \n",
    "# Since we use pytorch rather than autograd.np, we don't follow the above inheritance\n",
    "class NeuralKernel():\n",
    "    \"\"\"\n",
    "    A neural net + a isotropic Gaussian kernel.\n",
    "    Parameterization is the same as in the density of the standard normal\n",
    "    distribution. sigma2 is analogous to the variance.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, another_model, epsilonOPT, sigmaOPT, sigma0OPT, eps, cst):\n",
    "        self.model = model\n",
    "        self.another_model = another_model\n",
    "        self.epsilonOPT = epsilonOPT\n",
    "        self.sigmaOPT = sigmaOPT\n",
    "        self.sigma0OPT = sigma0OPT\n",
    "        self.eps = eps\n",
    "        self.cst = cst\n",
    "        self.params = list(model.parameters())+list(another_model.parameters())+[epsilonOPT]+[sigmaOPT]+[sigma0OPT]+[eps]+[cst]\n",
    "\n",
    "    def compute_feature_matrix(self, XY, V): # compute fea_pq = psi_p(V)-psi_q(V) = n x J,\n",
    "        \"\"\"\n",
    "        Evaluate the Gaussian kernel on the two 2d numpy arrays.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        XY : (n1+n2) x d numpy array\n",
    "        V : J x d numpy array\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        fea_pq : n x J numpy array\n",
    "        \"\"\"\n",
    "        len_X = XY.shape[0]/2\n",
    "        J = V.shape[0]\n",
    "\n",
    "        cst = self.cst\n",
    "        sigma0 = self.sigma0OPT ** 2\n",
    "        sigma = self.sigmaOPT ** 2\n",
    "        epsilon = torch.exp(self.epsilonOPT)/(1+torch.exp(self.epsilonOPT))\n",
    "\n",
    "\n",
    "        model_XY = self.model(XY)\n",
    "        another_model_XY = self.another_model(XY)\n",
    "        model_X = model_XY[0:len_X, :]\n",
    "        model_Y = model_XY[len_X:, :]\n",
    "        another_model_X = another_model_XY[0:len_X, :]\n",
    "        another_model_Y = another_model_XY[len_X:, :]\n",
    "\n",
    "        model_V = self.model(V)\n",
    "        another_model_V = self.another_model(V)\n",
    "\n",
    "        Dxv = Pdist2(model_X, model_V)\n",
    "        Dyv = Pdist2(model_Y, model_V)\n",
    "        Dxv_org = Pdist2(another_model_X, another_model_V)\n",
    "        Dyv_org = Pdist2(another_model_Y, another_model_V)\n",
    "\n",
    "        Kxv = cst*((1-epsilon) * torch.exp(-(Dxv / sigma0) - (Dxv_org / sigma))**L + epsilon * torch.exp(-Dxv_org / sigma))\n",
    "        Kyv = cst*((1-epsilon) * torch.exp(-(Dyv / sigma0) - (Dyv_org / sigma))**L + epsilon * torch.exp(-Dyv_org / sigma))\n",
    "\n",
    "        fea_pq = 1/np.sqrt(J) * (Kxv - Kyv)\n",
    "        return fea_pq\n",
    "        \n",
    "    def compute_UME_mean_variance(self, XY, V): # compute mean and var of UME(X,Y)\n",
    "        \"\"\"\n",
    "        Return the mean and variance of the reduced\n",
    "        test statistic = \\sqrt{n} UME(P, Q)^2\n",
    "        The estimator of the mean is unbiased (can be negative).\n",
    "\n",
    "        returns: (mean, variance)\n",
    "        \"\"\"\n",
    "        # get the feature matrices psi (correlated)\n",
    "        # fea_pq = psi_p(V)-psi_q(V) = n x J,\n",
    "        J = V.shape[0]\n",
    "        n = XY.shape[0]/2\n",
    "        fea_pq = self.compute_feature_matrix(XY, V) # n x J\n",
    "\n",
    "        # compute the mean \n",
    "        t1 = torch.sum( torch.mean(fea_pq, axis=0)**2) * (n/float(n-1))\n",
    "        t2 = torch.mean(torch.sum(fea_pq**2, axis=1)) / float(n-1)\n",
    "        UME_mean = t1 - t2\n",
    "\n",
    "        # compute the variance\n",
    "        mu = torch.mean(fea_pq, axis=0) # length-J vector\n",
    "        UME_variance = 4.0*torch.mean(np.dot(fea_pq, mu)**2) - 4.0*torch.sum(mu**2)**2\n",
    "\n",
    "        return UME_mean, UME_variance\n",
    "\n",
    "# define the loss function\n",
    "def power_criterion_mix(XY, V, kernel): #  objective to maximize, \n",
    "    \"\"\"\n",
    "    Note: compared to Jit18, here R is linear mixture of P and Q, we don't need R for the objective\n",
    "    \"\"\"\n",
    "    # compute the mean and variance of the test statistic\n",
    "    TEMP = kernel.compute_UME_mean_variance(XY, V)\n",
    "    # calculate objective\n",
    "    UME_mean = TEMP[0]\n",
    "    UME_var = TEMP[1]\n",
    "    UME_std = torch.sqrt(UME_var+10**(-8))\n",
    "    ratio = torch.div(UME_mean,UME_std)\n",
    "    return ratio\n",
    "\n",
    "# save ckeckpoint\n",
    "def save_model(V, kernel, epoch, folder_path):\n",
    "    path = folder_path+str(epoch)+'/'\n",
    "    try:\n",
    "        os.makedirs(path) \n",
    "    except:\n",
    "        pass\n",
    "    torch.save(kernel.model.state_dict(), path+'model.pt')\n",
    "    torch.save(kernel.another_model.state_dict(), path+'another_model.pt')\n",
    "    torch.save(kernel.epsilonOPT, path+'epsilonOPT.pt')\n",
    "    torch.save(kernel.sigmaOPT, path+'sigmaOPT.pt')\n",
    "    torch.save(kernel.sigma0OPT, path+'sigma0OPT.pt')\n",
    "    torch.save(kernel.cst, path+'cst.pt')\n",
    "    torch.save(V, path+'V.pt')\n",
    "\n",
    "# load checkpoint\n",
    "def load_model(folder_path, epoch=0):\n",
    "    print('loading model from epoch', epoch)\n",
    "    path = folder_path+str(epoch)+'/'\n",
    "    model = DN().cuda()\n",
    "    model.load_state_dict(torch.load(path+'model.pt'))\n",
    "    another_model = another_DN().cuda()\n",
    "    another_model.load_state_dict(torch.load(path+'another_model.pt'))\n",
    "    epsilonOPT = torch.load(path+'epsilonOPT.pt')\n",
    "    sigmaOPT = torch.load(path+'sigmaOPT.pt')\n",
    "    sigma0OPT = torch.load(path+'sigma0OPT.pt')\n",
    "    eps = torch.load(path+'eps.pt')\n",
    "    cst = torch.load(path+'cst.pt')\n",
    "    V = torch.load(path+'V.pt')\n",
    "    kernel = NeuralKernel(model, another_model, epsilonOPT, sigmaOPT, sigma0OPT, eps, cst)\n",
    "    return V, kernel\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmod import density, util, kernel\n",
    "from kmod import mctest as mct\n",
    "import matplotlib.pyplot as plt\n",
    "import autograd.numpy as np\n",
    "import autograd\n",
    "import scipy\n",
    "import kgof\n",
    "from kmod.mctest import SC_UME as SC_UME\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/math/home/eruisun\n",
      "background : signal = 5829122.0 : 5170877.0\n",
      "signal : 52.99202299927481 %\n"
     ]
    }
   ],
   "source": [
    "# dataset = np.load('~/LFI/Higgs/HIGGS.npy')\n",
    "%cd ~\n",
    "dataset = np.load('./LFI/Higgs/HIGGS.npy')\n",
    "print('background : signal =',np.sum(dataset[:,0]),':',dataset.shape[0]-np.sum(dataset[:,0]))\n",
    "print('signal :',np.sum(dataset[:,0])/dataset.shape[0]*100,'%')\n",
    "# split into signal and background\n",
    "dataset_P = dataset[dataset[:,0]==0][:, 1:] # background (5170877, 28)\n",
    "dataset_Q = dataset[dataset[:,0]==1][:, 1:] # signal     (5829122, 28) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random select train X,Y\n",
    "datptr = kgof.data.Data(dataset_P[np.random.choice(dataset_P.shape[0], 100_000)])\n",
    "datqtr = kgof.data.Data(dataset_Q[np.random.choice(dataset_Q.shape[0], 100_000)])\n",
    "# random select train Z\n",
    "background_events = dataset_P[np.random.choice(dataset_P.shape[0], 90_000)]\n",
    "signal_events = dataset_Q[np.random.choice(dataset_Q.shape[0], 10_000)]\n",
    "datrtr = kgof.data.Data(np.concatenate((signal_events, background_events), axis=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意这里PQR三个都被split了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training/test sets\n",
    "Xtr, Ytr, Ztr = [D.data() for D in [datptr, datqtr, datrtr]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the kernel and $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(validation_losses, epoch):\n",
    "    i = np.argmin(validation_losses)\n",
    "    # print(i)\n",
    "    if epoch - i > 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_3sample_criterion_and_kernel(prepared_batched_XY, # total_S, is a list\n",
    "                                          validation_XY, # validation set, is 2n*d\n",
    "                                        V, kernel, # params\n",
    "                                        N_epoch=100, learning_rate=0.01, momentum=0.9, # optimizer\n",
    "                                        print_every=10, # print and save checkpoint\n",
    "                                        early_stopping=None, # early stopping boolean function\n",
    "                                        fig_loss_epoch_name='', # name of the loss vs epoch figure\n",
    "                                        ):\n",
    "    params = list(kernel.params) + [V]\n",
    "    optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=momentum)\n",
    "    total_S = prepared_batched_XY\n",
    "    batches = len(total_S)\n",
    "    #############################\n",
    "    # start training\n",
    "    #############################\n",
    "    validation_ratio_list = np.ones([N_epoch])*np.inf\n",
    "    for t in range(N_epoch):\n",
    "        print('epoch',t)\n",
    "        order = np.random.permutation(batches)\n",
    "        for ind in tqdm(order):\n",
    "            optimizer.zero_grad()\n",
    "            # calculate parameters\n",
    "            XY = total_S[ind]\n",
    "            # calculate MMD\n",
    "            ratio = power_criterion_mix(XY, V, kernel)\n",
    "            obj = -ratio\n",
    "            # update parameters\n",
    "            obj.backward(retain_graph=False)\n",
    "            obj.step()     \n",
    "        #validation\n",
    "        with torch.torch.no_grad():\n",
    "            validation_ratio = power_criterion_mix(validation_XY, V, kernel).item()\n",
    "            validation_ratio_list.append(validation_ratio)\n",
    "            print('validation =', validation_ratio_list[t])\n",
    "        # print log\n",
    "        if t%print_every==0:\n",
    "            plt.plot(validation_ratio_list[:t])\n",
    "            plt.savefig(fig_loss_epoch_name)\n",
    "            plt.clf()\n",
    "            save_model(params)\n",
    "        # early stopping\n",
    "        if early_stopping(validation_ratio_list, t):\n",
    "            save_model(params)\n",
    "            plt.plot(validation_ratio_list[:t])\n",
    "            plt.savefig(fig_loss_epoch_name)\n",
    "            plt.clf()\n",
    "            return V, kernel\n",
    "    return V, kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "def train(n_tr, J=10, # size of X_tr, Y_tr and W=V\n",
    "        load_epoch=0, # load checkpoint if >0\n",
    "        batch_size=32, N_epoch=100, learning_rate=0.01, momentum=0.9, # optimizer\n",
    "        print_every=10, # print and save checkpoint\n",
    "        early_stopping=None, # early stopping boolean function\n",
    "        fig_loss_epoch_name='', # name of the loss vs epoch figure\n",
    "        seed = 0, # random seed\n",
    "        ):\n",
    "    n_backup = n_tr\n",
    "    try:\n",
    "        os.mkdir('./checkpoint n_tr=%d'%n_backup)\n",
    "    except:\n",
    "        pass\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    dtype = torch.float\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    batches = n_tr//batch_size + 1 \n",
    "    n = batches*batch_size  \n",
    "    X = dataset_P[0:n]\n",
    "    Y = dataset_Q[0:n]\n",
    "\n",
    "    # prepare training data\n",
    "    total_S = [(X[i*batch_size:(i+1)*batch_size], \n",
    "                Y[i*batch_size:(i+1)*batch_size]) \n",
    "                for i in range(batches)]\n",
    "    total_S = [MatConvert(np.concatenate((X, Y), axis=0), device, dtype) for (X, Y) in total_S]\n",
    "\n",
    "    # prepare NN and kernel and V=W \n",
    "    model = DN().cuda()\n",
    "    another_model = another_DN().cuda()\n",
    "\n",
    "    epsilonOPT = MatConvert(np.zeros(1), device, dtype) # set to 0 for MMD-G\n",
    "    epsilonOPT.requires_grad = True\n",
    "    sigmaOPT = MatConvert(np.sqrt(np.random.rand(1) * 0.3), device, dtype)\n",
    "    sigmaOPT.requires_grad = True\n",
    "    sigma0OPT = MatConvert(np.sqrt(np.random.rand(1) * 0.002), device, dtype)\n",
    "    sigma0OPT.requires_grad = True\n",
    "    eps=MatConvert(np.zeros((1,)), device, dtype)\n",
    "    eps.requires_grad = True\n",
    "    cst=MatConvert(1*np.ones((1,)), device, dtype)\n",
    "    cst.requires_grad = True\n",
    "    kernel = NeuralKernel(model, another_model, epsilonOPT, sigmaOPT, sigma0OPT, eps, cst)\n",
    "\n",
    "    V = MatConvert(np.random.randn(J, 28), device, dtype)\n",
    "\n",
    "    # load checkpoint if one want to start from a previous checkpoint\n",
    "    if load_epoch>0:\n",
    "        V, kernel = load_model(n_backup, load_epoch)\n",
    "        print('loaded')\n",
    "    kernel.model.eval()\n",
    "    kernel.another_model.eval()\n",
    "\n",
    "    # validation data\n",
    "    validation_XY = np.concatenate((dataset_P[n + np.random.choice(n, 10000, replace=False)], \n",
    "                            dataset_Q[n + np.random.choice(n, 10000, replace=False)]), axis=0)\n",
    "    validation_XY = MatConvert(validation_XY, device, dtype)\n",
    "\n",
    "    #############################\n",
    "    # start training\n",
    "    #############################\n",
    "    return optimize_3sample_criterion_and_kernel(total_S, # total_S, is a list\n",
    "                                          validation_XY, # validation set, is 2n*d\n",
    "                                        V, kernel, # params\n",
    "                                        N_epoch=100, learning_rate=0.01, momentum=0.9, # optimizer\n",
    "                                        print_every=10, # print and save checkpoint\n",
    "                                        early_stopping=None, # early stopping boolean function\n",
    "                                        fig_loss_epoch_name='', # name of the loss vs epoch figure\n",
    "                                        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "求几sigma不需要thres $T_\\alpha$\n",
    "求p-value就行\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再注意它们的p-value是用asym估计的，\n",
    "我们也是用Gaussian估计？\n",
    "一样？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time(arg):\n",
    "    # random select test X,Y\n",
    "    datpte = kgof.data.Data(dataset_P[np.random.choice(dataset_P.shape[0], 10_000)])\n",
    "    datqte = kgof.data.Data(dataset_Q[np.random.choice(dataset_Q.shape[0], 10_000)])\n",
    "    # random select test Z\n",
    "    # background_events = dataset_P[np.random.choice(dataset_P.shape[0], 1000)]\n",
    "    # signal_events = dataset_Q[np.random.choice(dataset_Q.shape[0], 100)]\n",
    "    if arg == 'null':\n",
    "        datrte =  kgof.data.Data(dataset_P[np.random.choice(dataset_P.shape[0], 10_000)])\n",
    "    elif arg == 'mix':\n",
    "        background_events = dataset_P[np.random.choice(dataset_P.shape[0], 100)]\n",
    "        signal_events = dataset_Q[np.random.choice(dataset_Q.shape[0], 9900)]\n",
    "        datrte = kgof.data.Data(np.concatenate((signal_events, background_events), axis=0))\n",
    "\n",
    "    # Gaussian kernel constructed with the optimized squared bandwidth\n",
    "    k_opt = kernel.KGauss(gw2_opt)\n",
    "    # Construct an object to represent the test. Use the test data here (not the training data!)\n",
    "    scume_opt3 = mct.SC_UME(datpte, datqte, k_opt, k_opt, V_opt, V_opt)\n",
    "    # returns a dictionary\n",
    "    test_result = scume_opt3.perform_test(datrte)\n",
    "    # display(test_result)\n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:36<00:00, 27.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "Monte = 100\n",
    "null_test_results = []\n",
    "test_results = []\n",
    "for i in trange(Monte):\n",
    "    test_results.append(test_one_time('mix'))\n",
    "    null_test_results.append(test_one_time('null'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of mix pvalues:  0.16720177721431645\n",
      "mean of null pvalues:  -0.1452878041857865\n"
     ]
    }
   ],
   "source": [
    "pvalues = np.array([r['pvalue'] for r in test_results])\n",
    "null_pvalues = np.array([r['pvalue'] for r in null_test_results])\n",
    "# transform into sigma unit\n",
    "from scipy.stats import norm\n",
    "pvalues = norm.ppf(1-pvalues)\n",
    "null_pvalues = norm.ppf(1-null_pvalues)\n",
    "# print mean\n",
    "print('mean of mix pvalues: ', np.mean(pvalues))\n",
    "print('mean of null pvalues: ', np.mean(null_pvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb62d3d5190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([r['test_stat'] for r in test_results], bins=50, alpha=0.5, label='mix')\n",
    "plt.hist([r['test_stat'] for r in null_test_results], bins=50, alpha=0.5, label='null')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用模拟值算pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 269.92it/s]\n"
     ]
    }
   ],
   "source": [
    "simulated_pvalues = []\n",
    "null_stats = [r['test_stat'] for r in null_test_results]\n",
    "for i in trange(Monte):\n",
    "    stat = test_results[i]['test_stat']\n",
    "    simulated_pvalues.append(np.mean(stat > np.array(null_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of simulated pvalues:  0.64281\n",
      "simulated pvalue in sigma:  0.36597999934450454\n"
     ]
    }
   ],
   "source": [
    "# simulated_pvalues = norm.ppf(1-np.array(simulated_pvalues))\n",
    "simulated_pvalue = np.mean(simulated_pvalues)\n",
    "print('mean of simulated pvalues: ', np.mean(simulated_pvalues))\n",
    "# into sigma unit\n",
    "simulated_pvalue = norm.ppf(simulated_pvalue)\n",
    "print('simulated pvalue in sigma: ', simulated_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     dataset = np.load('../HIGGS.npy')\n",
    "#     dataset_P = dataset[dataset[:,0]==0][:, 1:] # background (5829122, 28)\n",
    "#     dataset_Q = dataset[dataset[:,0]==1][:, 1:] # signal     (5170877, 28)\n",
    "\n",
    "#     n_list = [1300000, 1000000, 700000, 400000, 200000, 50000]\n",
    "#     for n in [1300000, 1000000, 700000, 400000, 200000, 50000]:\n",
    "#         for i in range(11):\n",
    "#             n_list.append(n+i)\n",
    "    \n",
    "#     for n in n_list:\n",
    "#         print('------ n =', n, '------')\n",
    "#         model,another_model,epsilonOPT,sigmaOPT,sigma0OPT,cst = train(n, \n",
    "#             N_epoch = 501,\n",
    "#             print_every = 5, \n",
    "#             batch_size = 1024, \n",
    "#             learning_rate = 2e-3, \n",
    "#             SGD = True, \n",
    "#             dataset_P = dataset_P, dataset_Q = dataset_Q,\n",
    "#             momentum=0.99, weight_decay=0.000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
