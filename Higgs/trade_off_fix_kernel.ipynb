{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/math/home/eruisun/software/anaconda/envs/LFI/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from utils_old import *\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from numba import cuda\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import pyroc\n",
    "import pandas as pd\n",
    "import gc\n",
    "from IPython.display import clear_output\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"  \n",
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.float32\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H = 500\n",
    "out= 100\n",
    "L = 1\n",
    "class DN(torch.nn.Module):\n",
    "    def __init__(self, H=300, out=100):\n",
    "        super(DN, self).__init__()\n",
    "        self.restored = False\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, out, bias=True),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.model(input)\n",
    "        return output\n",
    "\n",
    "class another_DN(torch.nn.Module):\n",
    "    def __init__(self, H=300, out=100):\n",
    "        super(another_DN, self).__init__()\n",
    "        self.restored = False\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, 28, bias=True),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.model(input) + input\n",
    "        return output\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, H=300, layers = 5):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.restored = False\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, 1, bias=True),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        if layers == 6:\n",
    "            self.model = torch.nn.Sequential(\n",
    "                torch.nn.Linear(28, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, 1, bias=True),\n",
    "                torch.nn.Sigmoid(),\n",
    "            )\n",
    "    def forward(self, input):\n",
    "        output = self.model(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('HIGGS.npy')\n",
    "dataset_P = dataset[dataset[:,0]==0][:, 1:] # background (5829122, 28)\n",
    "dataset_Q = dataset[dataset[:,0]==1][:, 1:] # signal     (5170877, 28)\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1300101\n",
    "path ='./checkpoint1300101/25/'\n",
    "model = DN(300, 100).cuda()\n",
    "another_model = another_DN(300, 100).cuda()\n",
    "model,another_model,epsilonOPT,sigmaOPT,sigma0OPT,cst = load_model(model, another_model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看(n_eval,m)\n",
    "# 选定 X_eval, Y_eval, 还要算phi=Eq[k(y,z)]-Ep[k(x,z)]的threhold在哪里\n",
    "# 必须手算!\n",
    "def generate_PQ(n_eval, Samples, batch_size = 10000, If_n_large_MonteCarlo = 1000):\n",
    "    X_eval = dataset_P[np.random.choice(dataset_P.shape[0], n_eval, replace=False)]\n",
    "    Y_eval = dataset_Q[np.random.choice(dataset_Q.shape[0], n_eval, replace=False)]\n",
    "    EKxx, EKyy, EKxy = compute_gamma(X_eval, Y_eval, model, another_model, epsilonOPT, sigmaOPT, sigma0OPT, cst, MonteCarlo=If_n_large_MonteCarlo)\n",
    "    # 算定下来X_eval, Y_eval之后phi的真实的分布\n",
    "    batches = (Samples-1)//batch_size + 1\n",
    "    P_scores = np.zeros(Samples)\n",
    "    Q_scores = np.zeros(Samples)\n",
    "    for i in trange(batches):\n",
    "        remain = batch_size\n",
    "        if i==batches-1:\n",
    "            remain = Samples - batch_size*(batches-1)\n",
    "        S_hand = np.concatenate((dataset_P[np.random.choice(dataset_P.shape[0], remain, replace=False)],\n",
    "                    dataset_Q[np.random.choice(dataset_Q.shape[0], remain, replace=False)]), axis=0)\n",
    "        S_hand = MatConvert(S_hand, device, dtype)\n",
    "        PQhat_hand = compute_score_func(S_hand, X_eval, Y_eval, \n",
    "                    model, another_model, epsilonOPT, sigmaOPT, sigma0OPT, cst,\n",
    "                    M = n_eval)\n",
    "        PQhat_hand = PQhat_hand.cpu().detach().numpy()\n",
    "        P_scores[i*batch_size: i*batch_size+remain] = PQhat_hand[:remain]\n",
    "        Q_scores[i*batch_size: i*batch_size+remain] = PQhat_hand[remain:]\n",
    "    return X_eval, Y_eval, P_scores, Q_scores, EKxx, EKyy, EKxy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意P_scores, Q_scores已经考虑到n_eval贡献的方差\n",
    "# EKxx, EKyy, EKxy完全是n_eval决定\n",
    "class PQ_data():\n",
    "    def __init__(self, P_scores, Q_scores, EKxx, EKyy, EKxy):\n",
    "        self.P_scores = P_scores\n",
    "        self.Q_scores = Q_scores\n",
    "        self.P_mean = np.mean(P_scores)\n",
    "        self.P_std = np.std(P_scores)\n",
    "        self.Q_mean = np.mean(Q_scores)\n",
    "        self.Q_std = np.std(Q_scores)\n",
    "        self.EKxx = EKxx\n",
    "        self.EKyy = EKyy\n",
    "        self.EKxy = EKxy\n",
    "    def pval_T_m_in_sigma(self, pi, m, use_gaussian, MonteCarlo):\n",
    "        T = pi*self.Q_mean + (1-pi)*self.P_mean\n",
    "        # use_gaussian: 是否用高斯近似, 0是用MonteCarlo近似，1是用高斯近似\n",
    "        P_scores = self.P_scores\n",
    "        mean = self.P_mean\n",
    "        std = self.P_std\n",
    "        if m==1:\n",
    "            p = np.mean(P_scores > T)\n",
    "            p = -scipy.stats.norm.ppf(p)\n",
    "        if use_gaussian:\n",
    "            p = (T-mean)/std*np.sqrt(m)\n",
    "        else:\n",
    "            T_mix_MonteCarlo_list = np.zeros(MonteCarlo)\n",
    "            for i in range(MonteCarlo):\n",
    "                idx = np.random.choice(P_scores.shape[0], m, replace=False)\n",
    "                T_mix_MonteCarlo_list[i] = np.mean(P_scores[idx])\n",
    "            p = np.mean(T_mix_MonteCarlo_list > T)\n",
    "            p = -scipy.stats.norm.ppf(p)\n",
    "        self.p = p\n",
    "        return p\n",
    "    def type_1_error_H0(self, pi, m, use_gaussian, MonteCarlo):\n",
    "        P_scores = self.P_scores\n",
    "        Q_scores = self.Q_scores\n",
    "        mean = self.P_mean\n",
    "        std = self.P_std\n",
    "        gamma = self.EKxx*(pi/2-1) + self.EKxy*(1-pi) + self.EKyy*(pi/2)\n",
    "        self.gamma = gamma\n",
    "        if m==1:\n",
    "            type_1_error = np.mean(P_scores > gamma)\n",
    "        if use_gaussian:\n",
    "            type_1_error = 1-scipy.stats.norm.cdf((gamma-mean)/std*np.sqrt(m))\n",
    "        else:\n",
    "            MonteCarlo_list = np.zeros(MonteCarlo)\n",
    "            for i in range(MonteCarlo):\n",
    "                idx = np.random.choice(P_scores.shape[0], m, replace=False)\n",
    "                MonteCarlo_list[i] = np.mean(P_scores[idx])\n",
    "            type_1_error = np.mean(MonteCarlo_list > gamma)\n",
    "        self.type_1_error = type_1_error\n",
    "        return type_1_error\n",
    "    def type_2_error_H1(self, pi, m, use_gaussian, MonteCarlo):\n",
    "        P_scores = self.P_scores\n",
    "        Q_scores = self.Q_scores\n",
    "        P_mean = self.P_mean\n",
    "        P_std = self.P_std\n",
    "        Q_mean = self.Q_mean\n",
    "        Q_std = self.Q_std\n",
    "        gamma = self.EKxx*(pi/2-1) + self.EKxy*(1-pi) + self.EKyy*(pi/2)\n",
    "        self.gamma = gamma\n",
    "        if m==1:\n",
    "            type_2_error = np.mean(Q_scores < gamma)\n",
    "        if use_gaussian:\n",
    "            mean = Q_mean*pi + P_mean*(1-pi)\n",
    "            std = np.sqrt(pi*Q_std**2 + (1-pi)*P_std**2)\n",
    "            type_2_error = scipy.stats.norm.cdf((gamma-mean)/std*np.sqrt(m))\n",
    "        else:\n",
    "            MonteCarlo_list = np.zeros(MonteCarlo)\n",
    "            for i in range(MonteCarlo):\n",
    "                Signals_idx = np.random.choice(Q_scores.shape[0], int(m*pi), replace=False)\n",
    "                Backgrounds_idx = np.random.choice(P_scores.shape[0], int(m*(1-pi)), replace=False)\n",
    "                MonteCarlo_list[i] = np.mean(np.concatenate((Q_scores[Signals_idx], P_scores[Backgrounds_idx])))\n",
    "            type_2_error = np.mean(MonteCarlo_list < gamma)\n",
    "        self.type_2_error = type_2_error\n",
    "        return type_2_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pi=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi= 0.1\n",
    "n_list = np.array([2, 6, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000,])\n",
    "m_list = np.array([1, 2, 6, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000,])\n",
    "\n",
    "n_list = 10**np.linspace(0.5, 4.3, 40)\n",
    "n_list = n_list.astype(int)\n",
    "m_list = 10**np.linspace(0.5, 4.3, 40)\n",
    "m_list = m_list.astype(int)\n",
    "\n",
    "repeat_sample_n_eval = 2000\n",
    "Pval_mat = np.zeros((len(n_list), len(m_list),repeat_sample_n_eval))\n",
    "Type1_mat = np.zeros((len(n_list), len(m_list),repeat_sample_n_eval))\n",
    "Type2_mat = np.zeros((len(n_list), len(m_list),repeat_sample_n_eval))\n",
    "Use_Gaussian = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(repeat_sample_n_eval):\n",
    "    for i in trange(len(n_list)):\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "            n_eval = n_list[i]\n",
    "            X_eval, Y_eval, P_scores, Q_scores, EKxx, EKyy, EKxy = generate_PQ(n_eval, Samples=20000, batch_size=4000, If_n_large_MonteCarlo=10)\n",
    "            My_class = PQ_data(P_scores, Q_scores, EKxx, EKyy, EKxy)\n",
    "            for j in range(len(m_list)):\n",
    "                m = m_list[j]\n",
    "                Pval_mat[i,j,r] += My_class.pval_T_m_in_sigma(pi, m, use_gaussian=Use_Gaussian, MonteCarlo=0)\n",
    "                Type1_mat[i,j,r] += My_class.type_1_error_H0(pi, m, use_gaussian=Use_Gaussian, MonteCarlo=0)\n",
    "                Type2_mat[i,j,r] += My_class.type_2_error_H1(pi, m, use_gaussian=Use_Gaussian, MonteCarlo=0)\n",
    "            del My_class, X_eval, Y_eval, P_scores, Q_scores, EKxx, EKyy, EKxy\n",
    "            gc.collect()\n",
    "        clear_output()   \n",
    "        print(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "# plt.subplot(1,4,1)\n",
    "# plt.contourf(np.log10(n_list), np.log10(m_list), Pval_mat.T, levels=20)\n",
    "# plt.colorbar()\n",
    "# plt.xlabel('$lg(n_{eval})$')\n",
    "# plt.ylabel('lg(m)')\n",
    "# plt.title('p-value')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.contourf(np.log10(n_list), np.log10(m_list), Type1_mat.T, levels=20)\n",
    "plt.colorbar()\n",
    "plt.xlabel('$lg(n_{eval})$')\n",
    "plt.ylabel('lg(m)')\n",
    "plt.title('$P_{H_0}(fail)$')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.contourf(np.log10(n_list), np.log10(m_list), Type2_mat.T, levels=20)\n",
    "plt.colorbar()\n",
    "plt.xlabel('$lg(n_{eval})$')\n",
    "plt.ylabel('lg(m)')\n",
    "plt.title('$P_{H_1}(fail)$')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.contourf(np.log10(n_list), np.log10(m_list), Type1_mat.T+Type2_mat.T, levels=20)\n",
    "plt.colorbar()\n",
    "plt.xlabel('lg(n_eval)')\n",
    "plt.ylabel('lg(m)')\n",
    "plt.title('$\\Sigma P(fail)$')\n",
    "\n",
    "plt.suptitle(r'Fix kernel ($n_{train}=1.3e6$), Use Gaussian Approx='+str(Use_Gaussian)+', $\\pi$='+str(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type123 = Type1_mat+Type2_mat\n",
    "plt.matshow(type123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "62ea4cb577f3452d4896231ded751324f6550842c2f7ee362c371c3b628fa6a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
