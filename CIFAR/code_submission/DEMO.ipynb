{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jtz20\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.utils import check_random_state\n",
    "from utils import *\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "class ConvNet_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_CIFAR10, self).__init__()\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block =([nn.Conv2d(in_filters, out_filters, 3, 2, 1), \n",
    "                     nn.LeakyReLU(0.2, inplace=True),  \n",
    "                     nn.Dropout2d(0)])\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Unflatten(1,(3,32,32)),\n",
    "            *discriminator_block(3, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "        ds_size = 2\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 300))\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        feature = self.adv_layer(out)\n",
    "        return feature\n",
    "    \n",
    "def crit(mmd_val, mmd_var, liuetal=True, Sharpe=False):\n",
    "    if liuetal:\n",
    "        mmd_std_temp = torch.sqrt(mmd_var+10**(-8)) #this is std\n",
    "        return -1 * torch.div(mmd_val, mmd_std_temp)\n",
    "    elif Sharpe:\n",
    "        return mmd_val - 2.0 * mmd_var\n",
    "\n",
    "def mmdGT(X, Y, model_u, n, sigma, sigma0, ep):\n",
    "    S = torch.cat((X, Y), dim=0)\n",
    "    Fea = model_u(S)\n",
    "    n = X.shape[0]\n",
    "    return MMD_General(Fea, n, S, sigma, sigma0, ep, use1sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 3072) (15000, 3072) (6000, 3072) (6000, 3072)\n"
     ]
    }
   ],
   "source": [
    "def load_diffusion_cifar_32():\n",
    "    diffusion = np.load(\"../../Diffusion/ddpm_generated_images2.npy\").transpose(0,3,1,2)\n",
    "    cifar10 = np.load('../../data/cifar_data.npy')\n",
    "    dataset_P = diffusion.reshape(diffusion.shape[0], -1)\n",
    "    dataset_Q = cifar10.reshape(cifar10.shape[0], -1)\n",
    "    return dataset_P, dataset_Q[:10000, :], dataset_Q[10000:, :]\n",
    "\n",
    "DP, DQ_1, DQ_2 = load_diffusion_cifar_32()\n",
    "mix_rate=2 #For each DP, match with mix_rate*DQ data points\n",
    "\n",
    "test_DP1=np.concatenate((DP[:2000, :], DQ_1[:4000, :]), axis=0)\n",
    "test_DQ1=DQ_1[4000: 10000, :]\n",
    "\n",
    "train_DP1=np.concatenate((DP[2000:7000, :], DQ_2[:10000, :]), axis=0)\n",
    "train_DQ1=DQ_2[10000: 25000, :]\n",
    "\n",
    "print(train_DP1.shape, train_DQ1.shape, test_DP1.shape, test_DQ1.shape)\n",
    "#generate a random shuffle over train_DP1, print the first item\n",
    "train_DP1 = train_DP1[np.random.choice(train_DP1.shape[0], train_DP1.shape[0], replace=False), :]\n",
    "train_DQ1 = train_DQ1[np.random.choice(train_DQ1.shape[0], train_DQ1.shape[0], replace=False), :]\n",
    "test_DP1 = test_DP1[np.random.choice(test_DP1.shape[0], test_DP1.shape[0], replace=False), :]\n",
    "test_DQ1 = test_DQ1[np.random.choice(test_DQ1.shape[0], test_DQ1.shape[0], replace=False), :]\n",
    "\n",
    "DP1_t = MatConvert(train_DP1, device, dtype)\n",
    "DQ1_t = MatConvert(train_DQ1, device, dtype)\n",
    "DP2_t = MatConvert(test_DP1, device, dtype)\n",
    "DQ2_t = MatConvert(test_DQ1, device, dtype)\n",
    "\n",
    "def gen_fun1(n): #n at most 15000\n",
    "    X = train_DP1[np.random.choice(train_DP1.shape[0], n, replace=False), :]\n",
    "    Y = train_DQ1[np.random.choice(train_DQ1.shape[0], n, replace=False), :]\n",
    "    return X, Y\n",
    "def gen_fun2(n): #n at most 6000\n",
    "    X = test_DP1[np.random.choice(test_DP1.shape[0], n, replace=False), :]\n",
    "    Y = test_DQ1[np.random.choice(test_DQ1.shape[0], n, replace=False), :]\n",
    "    return X, Y\n",
    "\n",
    "def gen_fun1_t(n):\n",
    "    X = DP1_t[np.random.choice(DP1_t.shape[0], n, replace=False), :]\n",
    "    Y = DQ1_t[np.random.choice(DQ1_t.shape[0], n, replace=False), :]\n",
    "    return X, Y\n",
    "\n",
    "def gen_fun2_t(n):\n",
    "    X = DP2_t[np.random.choice(DP2_t.shape[0], n, replace=False), :]\n",
    "    Y = DQ2_t[np.random.choice(DQ2_t.shape[0], n, replace=False), :]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_d(n, learning_rate=5e-4, N_epoch=50, print_every=20, batch_size=32):  \n",
    "    batches=n//batch_size\n",
    "    assert n%batch_size==0\n",
    "    print(\"##### Starting N_epoch=%d epochs per data trial #####\"%(N_epoch))\n",
    "    if True:\n",
    "        X, Y = gen_fun1(n)\n",
    "        total_S=[(X[i*batch_size:i*batch_size+batch_size], \n",
    "                    Y[i*batch_size:i*batch_size+batch_size]) for i in range(batches)]\n",
    "        total_S=[MatConvert(np.concatenate((X, Y), axis=0), device, dtype) for (X, Y) in total_S]\n",
    "        model_u = ConvNet_CIFAR10().cuda()\n",
    "        epsilonOPT = MatConvert(np.array([-1.0]), device, dtype)\n",
    "        epsilonOPT.requires_grad = True\n",
    "        sigmaOPT = MatConvert(np.array([10000.0]), device, dtype)\n",
    "        sigmaOPT.requires_grad = True\n",
    "        sigma0OPT = MatConvert(np.array([0.1]), device, dtype)\n",
    "        sigma0OPT.requires_grad = True\n",
    "        cst=MatConvert(np.ones((1,)), device, dtype) # set to 1 to meet liu etal objective\n",
    "        optimizer_u = torch.optim.Adam(list(model_u.parameters())+[epsilonOPT]+[sigmaOPT]+[sigma0OPT], lr=learning_rate)\n",
    "        for t in range(N_epoch):\n",
    "            for ind in range(batches):\n",
    "                ep = torch.exp(epsilonOPT)/(1+torch.exp(epsilonOPT))\n",
    "                sigma = sigmaOPT ** 2\n",
    "                sigma0_u = sigma0OPT ** 2\n",
    "                S=total_S[ind]\n",
    "                modelu_output = model_u(S) \n",
    "                TEMP = MMDu(modelu_output, batch_size, S, sigma, sigma0_u, ep, cst)\n",
    "                mmd_val = TEMP[0]\n",
    "                mmd_var = TEMP[1]\n",
    "                STAT_u = crit(mmd_val, mmd_var) \n",
    "                optimizer_u.zero_grad()\n",
    "                STAT_u.backward(retain_graph=True)\n",
    "                optimizer_u.step()\n",
    "        return model_u, torch.exp(epsilonOPT)/(1+torch.exp(epsilonOPT)), sigmaOPT ** 2, sigma0OPT ** 2, torch.tensor(X).to(device, dtype), torch.tensor(Y).to(device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Starting N_epoch=80 epochs per data trial #####\n",
      "Under this trained kernel, we run N = 300 times LFI: \n",
      "start testing m = 64\n",
      "n, m= 1920  64 --- P(max|Z~X):  0.7266666666666667\n",
      "n, m= 1920  64 --- P(max|Z~Y):  0.7266666666666667\n",
      "n, m= 1920  64 --- P(95|Z~X):  0.9566666666666667\n",
      "n, m= 1920  64 --- P(95|Z~Y):  0.35\n",
      "n, m= 1920  64 --- P(p|Z~X):  0.4851666666666667\n",
      "n, m= 1920  64 --- P(p|Z~Y):  0.7778666666666667\n",
      "start testing m = 96\n",
      "n, m= 1920  96 --- P(max|Z~X):  0.7333333333333333\n",
      "n, m= 1920  96 --- P(max|Z~Y):  0.8133333333333334\n",
      "n, m= 1920  96 --- P(95|Z~X):  0.9266666666666666\n",
      "n, m= 1920  96 --- P(95|Z~Y):  0.43666666666666665\n",
      "n, m= 1920  96 --- P(p|Z~X):  0.4919333333333333\n",
      "n, m= 1920  96 --- P(p|Z~Y):  0.8507666666666668\n",
      "start testing m = 128\n",
      "n, m= 1920  128 --- P(max|Z~X):  0.71\n",
      "n, m= 1920  128 --- P(max|Z~Y):  0.8666666666666667\n",
      "n, m= 1920  128 --- P(95|Z~X):  0.9333333333333333\n",
      "n, m= 1920  128 --- P(95|Z~Y):  0.52\n",
      "n, m= 1920  128 --- P(p|Z~X):  0.5135666666666666\n",
      "n, m= 1920  128 --- P(p|Z~Y):  0.8845999999999999\n",
      "start testing m = 192\n",
      "n, m= 1920  192 --- P(max|Z~X):  0.7866666666666666\n",
      "n, m= 1920  192 --- P(max|Z~Y):  0.9066666666666666\n",
      "n, m= 1920  192 --- P(95|Z~X):  0.93\n",
      "n, m= 1920  192 --- P(95|Z~Y):  0.6766666666666666\n",
      "n, m= 1920  192 --- P(p|Z~X):  0.48800000000000004\n",
      "n, m= 1920  192 --- P(p|Z~Y):  0.9255333333333332\n",
      "start testing m = 256\n",
      "n, m= 1920  256 --- P(max|Z~X):  0.7733333333333333\n",
      "n, m= 1920  256 --- P(max|Z~Y):  0.9066666666666666\n",
      "n, m= 1920  256 --- P(95|Z~X):  0.9366666666666666\n",
      "n, m= 1920  256 --- P(95|Z~Y):  0.7766666666666666\n",
      "n, m= 1920  256 --- P(p|Z~X):  0.5271\n",
      "n, m= 1920  256 --- P(p|Z~Y):  0.9452999999999999\n",
      "start testing m = 384\n",
      "n, m= 1920  384 --- P(max|Z~X):  0.8833333333333333\n",
      "n, m= 1920  384 --- P(max|Z~Y):  0.98\n",
      "n, m= 1920  384 --- P(95|Z~X):  0.9633333333333334\n",
      "n, m= 1920  384 --- P(95|Z~Y):  0.9133333333333333\n",
      "n, m= 1920  384 --- P(p|Z~X):  0.49286666666666673\n",
      "n, m= 1920  384 --- P(p|Z~Y):  0.9843666666666667\n"
     ]
    }
   ],
   "source": [
    "n=1920\n",
    "N=300\n",
    "m_list=[64, 96, 128, 192, 256, 384]\n",
    "model_u, ep, sigma, sigma0, X_t, Y_t=train_d(n, learning_rate=5e-4, N_epoch=80, print_every=20, batch_size=32)\n",
    "with torch.no_grad():\n",
    "        H_u = np.zeros(N) \n",
    "        H_v = np.zeros(N)\n",
    "        R_u = np.zeros(N)\n",
    "        R_v = np.zeros(N)\n",
    "        P_u = np.zeros(N)\n",
    "        P_v = np.zeros(N)\n",
    "        print(\"Under this trained kernel, we run N = %d times LFI: \"%N)\n",
    "        for i in range(len(m_list)):\n",
    "            print(\"start testing m = %d\"%m_list[i])\n",
    "            m = m_list[i]\n",
    "            for k in range(N):     \n",
    "                stat=[]\n",
    "                for j in range(100):\n",
    "                        Z_temp, _ = gen_fun2_t(m) ###DEMO PURPOSES ONLY: check Phase 2, Algorithm 1,  in our paper\n",
    "                        mmd_XZ = mmdGT(X_t, Z_temp, model_u, n, sigma, sigma0, ep)[0] \n",
    "                        mmd_YZ = mmdGT(Y_t, Z_temp, model_u, n, sigma, sigma0, ep)[0]\n",
    "                        stat.append(float(mmd_XZ - mmd_YZ))\n",
    "                stat = np.sort(stat)\n",
    "                thres = stat[94]\n",
    "                Z1, Z2 = gen_fun2_t(m)\n",
    "                mmd_XZ = mmdGT(X_t, Z1, model_u, n, sigma, sigma0, ep)[0] \n",
    "                mmd_YZ = mmdGT(Y_t, Z1, model_u, n, sigma, sigma0, ep)[0] \n",
    "                H_u[k] = mmd_XZ - mmd_YZ < 0.0\n",
    "                R_u[k] = mmd_XZ - mmd_YZ < thres\n",
    "                P_u[k] = np.searchsorted(stat, float(mmd_XZ - mmd_YZ), side=\"right\")/100.0\n",
    "                mmd_XZ = mmdGT(X_t, Z2, model_u, n, sigma, sigma0, ep)[0] \n",
    "                mmd_YZ = mmdGT(Y_t, Z2, model_u, n, sigma, sigma0, ep)[0] \n",
    "                H_v[k] = mmd_XZ - mmd_YZ > 0.0\n",
    "                R_v[k] = mmd_XZ - mmd_YZ > thres\n",
    "                P_v[k] = np.searchsorted(stat, float(mmd_XZ - mmd_YZ), side=\"right\")/100.0\n",
    "            print(\"n, m=\",str(n)+str('  ')+str(m),\"--- P(max|Z~X): \", H_u.mean())\n",
    "            print(\"n, m=\",str(n)+str('  ')+str(m),\"--- P(max|Z~Y): \", H_v.mean())\n",
    "            print(\"n, m=\",str(n)+str('  ')+str(m),\"--- P(95|Z~X): \", R_u.mean())\n",
    "            print(\"n, m=\",str(n)+str('  ')+str(m),\"--- P(95|Z~Y): \", R_v.mean())\n",
    "            print(\"n, m=\",str(n)+str('  ')+str(m),\"--- P(p|Z~X): \", P_u.mean())\n",
    "            print(\"n, m=\",str(n)+str('  ')+str(m),\"--- P(p|Z~Y): \", P_v.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "def find_percentile(m, p, percentile=0.95):\n",
    "    return binom.ppf(percentile, m, p)/m\n",
    "def find_p_value(m, p, p_obs):\n",
    "    return binom.cdf(p_obs*m, m, p)\n",
    "def EPV(m, p_1, p_2):\n",
    "    result=0\n",
    "    for _ in range(50000):\n",
    "        #p_obs is random observation Binomial(m, p_2)/m\n",
    "        p_obs=np.random.binomial(m, p_2)/m\n",
    "        result+=binom.cdf(p_obs*m, m, p_1)\n",
    "    return result/50000\n",
    "def MMD_LFI(Fea, n, Fea_org, sigma, sigma0=0.1, epsilon=10 ** (-10), cst = 1.0, is_smooth=True, one_sample=False):\n",
    "    X = Fea[0:n, :] # fetch the sample 1 (features of deep networks)\n",
    "    Y = Fea[n:2*n, :] # fetch the sample 2 (features of deep networks)\n",
    "    Z = Fea[2*n:, :] # fetch the sample 3 (features of deep networks)\n",
    "    X_org = Fea_org[0:n, :] # fetch the original sample 1\n",
    "    Y_org = Fea_org[n:2*n, :] # fetch the original sample 2\n",
    "    Z_org = Fea_org[2*n:, :] # fetch the original sample 3\n",
    "    Dxx = Pdist2(X, X)\n",
    "    Dyy = Pdist2(Y, Y)\n",
    "    Dxz = Pdist2(X, Z)\n",
    "    Dyz = Pdist2(Y, Z)\n",
    "    Dxx_org = Pdist2(X_org, X_org)\n",
    "    Dyy_org = Pdist2(Y_org, Y_org)\n",
    "    Dxz_org = Pdist2(X_org, Z_org)\n",
    "    Dyz_org = Pdist2(Y_org, Z_org)\n",
    "    Kx = cst*((1-epsilon) * torch.exp(-(Dxx / sigma0) - (Dxx_org / sigma)) + epsilon * torch.exp(-Dxx_org / sigma))\n",
    "    Ky = cst*((1-epsilon) * torch.exp(-(Dyy / sigma0) - (Dyy_org / sigma)) + epsilon * torch.exp(-Dyy_org / sigma))\n",
    "    Kxz = cst*((1-epsilon) * torch.exp(-(Dxz / sigma0) - (Dxz_org / sigma)) + epsilon * torch.exp(-Dxz_org / sigma))\n",
    "    Kyx = cst*((1-epsilon) * torch.exp(-(Dyz / sigma0) - (Dyz_org / sigma)) + epsilon * torch.exp(-Dyz_org / sigma))\n",
    "    return MMD_LFI_SQUARE(Kx, Ky, Kxz, Kyx, n, len(Fea)-2*n, one_sample_U=one_sample)\n",
    "def MMD_LFI_SQUARE(Kx, Ky, Kyz, Kxz, batch_n, batch_m, one_sample_U=False):\n",
    "    nx = batch_n\n",
    "    nz = batch_m\n",
    "    if one_sample_U:\n",
    "        xx = torch.div((torch.sum(Kx) - torch.sum(torch.diag(Kx))), (nx * (nx - 1)))\n",
    "        yy = torch.div((torch.sum(Ky) - torch.sum(torch.diag(Ky))), (nx * (nx - 1)))\n",
    "        xz = torch.div((torch.sum(Kxz) - torch.sum(torch.diag(Kxz))), (nx * (nz - 1)))\n",
    "        yz = torch.div((torch.sum(Kyz) - torch.sum(torch.diag(Kyz))), (nx * (nz - 1)))\n",
    "        mmd2 = xx - yy + 2* xz - 2* yz\n",
    "    else:\n",
    "        xx = torch.div((torch.sum(Kx) - torch.sum(torch.diag(Kx))), (nx * (nx - 1)))\n",
    "        yy = torch.div((torch.sum(Ky) - torch.sum(torch.diag(Ky))), (nx * (nx - 1)))\n",
    "        xz = torch.div((torch.sum(Kxz)), (nx * nz))\n",
    "        yz = torch.div((torch.sum(Kyz)), (nx * nz))\n",
    "        mmd2 = xx - yy - 2* xz + 2* yz\n",
    "    return mmd2\n",
    "def K(x, A, t=1, one_sample=False):\n",
    "    X_t=A[0]\n",
    "    Y_t=A[1]\n",
    "    Z_t=x.reshape(t,-1)\n",
    "    return float(MMD_LFI(torch.cat((X_t, Y_t, Z_t), 0), len(X_t), torch.cat((X_t, Y_t, Z_t), 0), sigma, sigma0, ep, one_sample=one_sample) )\n",
    "def find_threshold(arr1, arr2):\n",
    "    n=len(arr1)\n",
    "    max_val=0\n",
    "    max_i=0\n",
    "    for i in range(int(0.2*n), int(0.8*n)):\n",
    "        j=np.searchsorted(arr2, arr1[i], side='right')\n",
    "        val=(i-j)**2/(i*(n-i))\n",
    "        if val>max_val:\n",
    "            max_val, max_i=val, i\n",
    "    return arr1[max_i]\n",
    "def find_threshold_full(cal_data, eva_data):\n",
    "    stat_X=[]\n",
    "    stat_Y=[]\n",
    "    for i in range(len(eva_data[0])):\n",
    "        X=eva_data[0][i]\n",
    "        Y=eva_data[1][i]\n",
    "        stat_X.append(K(X, cal_data))\n",
    "        stat_Y.append(K(Y, cal_data))\n",
    "    sort_X=np.sort(stat_X)\n",
    "    sort_Y=np.sort(stat_Y)\n",
    "    return find_threshold(sort_X, sort_Y)\n",
    "def evaluat(Z, cal_data, t):\n",
    "    x=0\n",
    "    A=[]\n",
    "    for ind in range(len(Z)):\n",
    "        A.append(K(Z[ind], cal_data))\n",
    "        x+=(A[-1]<t)\n",
    "    return x/len(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_1, p_2= 0.4201666666666667 0.4806666666666667\n",
      "n, m= 1920  256 --- P(95|Z~Y):  0.5765752932341279\n",
      "n, m= 1920  256 --- P(Ep|Z~Y):  0.9225572315829828\n"
     ]
    }
   ],
   "source": [
    "cal_data=(X_t, Y_t)\n",
    "eva_data=gen_fun2_t(n)\n",
    "threshold=find_threshold_full(cal_data, eva_data)\n",
    "Z1, Z2 = gen_fun2_t(6000) #entire set of test data\n",
    "p_1=evaluat(Z1, cal_data, threshold)\n",
    "p_2=evaluat(Z2, cal_data, threshold)\n",
    "print('p_1, p_2=', p_1, p_2) #the thresholded bias for each hypothesis\n",
    "m=256\n",
    "print(\"n, m=\",str(n)+str('  ')+str(m),\"--- P(95|Z~Y): \", 1-find_p_value(m, p_2, find_percentile(m, p_1)))\n",
    "print(\"n, m=\",str(n)+str('  ')+str(m),\"--- P(Ep|Z~Y): \", EPV(m, p_1, p_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01224ac206ca873c9d727f72740b1f7e0424046de25ebf62ad6fe62ff6f16ba9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
