{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/math/home/eruisun/software/anaconda/envs/LFI/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from utils import *\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from numba import cuda\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import pyroc\n",
    "import pandas as pd\n",
    "import gc\n",
    "from IPython.display import clear_output\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"  \n",
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.float32\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H = 300\n",
    "out= 100\n",
    "L = 1\n",
    "class DN(torch.nn.Module):\n",
    "    def __init__(self, H=300, out=100):\n",
    "        super(DN, self).__init__()\n",
    "        self.restored = False\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, out, bias=True),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.model(input)\n",
    "        return output\n",
    "\n",
    "class another_DN(torch.nn.Module):\n",
    "    def __init__(self, H=300, out=100):\n",
    "        super(another_DN, self).__init__()\n",
    "        self.restored = False\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, 28, bias=True),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.model(input) + input\n",
    "        return output\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, H=300, layers = 5, tanh=False):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.restored = False\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, 1, bias=True),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        if layers == 6:\n",
    "            self.model = torch.nn.Sequential(\n",
    "                torch.nn.Linear(28, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(H, 1, bias=True),\n",
    "                torch.nn.Sigmoid(),\n",
    "            )\n",
    "        if tanh:\n",
    "            self.model = torch.nn.Sequential(\n",
    "                torch.nn.Linear(28, H, bias=True),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(H, H, bias=True),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(H, 1, bias=True),\n",
    "                torch.nn.Sigmoid()\n",
    "            )\n",
    "    def forward(self, input):\n",
    "        output = self.model(input)\n",
    "        return output\n",
    "\n",
    "class DN_LBI(torch.nn.Module):\n",
    "    def __init__(self, H):\n",
    "        super(DN_LBI, self).__init__()\n",
    "        self.restored = False\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(H, 1, bias=True),\n",
    "        )\n",
    "        self.out = torch.nn.Sigmoid()\n",
    "    def forward(self, input):\n",
    "        output = self.model(input)\n",
    "        output = self.out(output)\n",
    "        return output\n",
    "    def LBI(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('HIGGS.npy')\n",
    "dataset_P = dataset[dataset[:,0]==0][:, 1:] # background (5829122, 28)\n",
    "dataset_Q = dataset[dataset[:,0]==1][:, 1:] # signal     (5170877, 28)\n",
    "dataset_P = MatConvert(dataset_P, device=device, dtype=dtype)\n",
    "dataset_Q = MatConvert(dataset_Q, device=device, dtype=dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p(n_train, path, method, force_thres = None):\n",
    "    if method == 'Scheffe':\n",
    "        model = Classifier(300, 5).cuda()\n",
    "    if method == 'Gaussian':\n",
    "        model = DN(300, 100).cuda()\n",
    "    if method == 'Fea_Gau':\n",
    "        model = DN(300, 100).cuda()\n",
    "    if method == 'Mix':\n",
    "        model = DN(300, 100).cuda()\n",
    "    if method == 'Res_Net':\n",
    "        model = DN(300, 100).cuda()\n",
    "    if method == 'LBI':\n",
    "        model = DN_LBI(300).cuda()\n",
    "    another_model = another_DN(300, 100).cuda()\n",
    "    model,another_model,epsilonOPT,sigmaOPT,sigma0OPT,cst = load_model(model, another_model, path)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    #####################\n",
    "    p_soft_list = np.zeros(10)\n",
    "    p_hard_list = np.zeros(10)\n",
    "    n = n_train\n",
    "    for i in range(10):\n",
    "        n_test = min(n,20000)\n",
    "        n_eval = 100000\n",
    "        idx = np.random.choice(dataset_P.shape[0]-n_train, n_eval+n_test, replace=False) + n_train\n",
    "        idy = np.random.choice(dataset_Q.shape[0]-n_train, n_eval+n_test, replace=False) + n_train\n",
    "        X_test = dataset_P[np.random.choice(n_train, n_test, replace=False)]\n",
    "        Y_test = dataset_Q[np.random.choice(n_train, n_test, replace=False)]\n",
    "        # X_test = dataset_P[0:n_eval]\n",
    "        # Y_test = dataset_Q[0:n_eval]\n",
    "        # X_test = MatConvert(X_test, device, dtype)\n",
    "        # Y_test = MatConvert(Y_test, device, dtype)\n",
    "        X_eval = dataset_P[idx][n_test:n_test+n_eval]\n",
    "        Y_eval = dataset_Q[idy][n_test:n_test+n_eval]\n",
    "        # X_eval = MatConvert(X_eval, device, dtype)\n",
    "        # Y_eval = MatConvert(Y_eval, device, dtype)\n",
    "        X_test_eval = X_test\n",
    "        Y_test_eval = Y_test\n",
    "\n",
    "        if force_thres!= None:\n",
    "            n_eval = X_eval.shape[0]\n",
    "            batch_size = 10000\n",
    "            X_scores = torch.zeros(n_eval)\n",
    "            Y_scores = torch.zeros(n_eval)\n",
    "            for j in range(1+(n_eval-1)//batch_size):\n",
    "                X_scores[j*batch_size : (j+1)*batch_size] =  compute_score_func(X_eval[j*batch_size : (j+1)*batch_size], X_test, Y_test,\n",
    "                                                                model, another_model, epsilonOPT, sigmaOPT, sigma0OPT, cst) \n",
    "                Y_scores[j*batch_size : (j+1)*batch_size] =  compute_score_func(Y_eval[j*batch_size : (j+1)*batch_size], X_test, Y_test,\n",
    "                                                                model, another_model, epsilonOPT, sigmaOPT, sigma0OPT, cst)\n",
    "            gc.collect()\n",
    "            pval = get_pval(X_scores, Y_scores, thres = force_thres, norm_or_binom=False)\n",
    "            p_soft_list[i] = 0\n",
    "            p_hard_list[i] = pval\n",
    "            continue\n",
    "        \n",
    "        p_soft = get_pval_at_once(X_test, Y_test, X_test_eval, Y_test_eval, X_eval, Y_eval,\n",
    "                        model,another_model,epsilonOPT,sigmaOPT,sigma0OPT,cst,\n",
    "                        batch_size = 10000,\n",
    "                        norm_or_binom=True)\n",
    "        p_hard = get_pval_at_once(X_test, Y_test, X_test_eval, Y_test_eval, X_eval, Y_eval,\n",
    "                        model,another_model,epsilonOPT,sigmaOPT,sigma0OPT,cst,\n",
    "                        batch_size = 10000,\n",
    "                        norm_or_binom=False)\n",
    "        p_soft_list[i] = p_soft\n",
    "        p_hard_list[i] = p_hard\n",
    "        clear_output(wait=True)\n",
    "    return p_soft_list, p_hard_list\n",
    "\n",
    "def get_p_from_10_model(n, method, models = 10, force_thres = None):\n",
    "    p_soft_mat = np.zeros((models,10))\n",
    "    p_hard_mat = np.zeros((models,10))\n",
    "    for i in trange(models):\n",
    "        path = './'+method+'/checkpoint'+str(n+i)+'/0/'\n",
    "        p_soft_mat[i], p_hard_mat[i] = get_p(n+i, path, method, force_thres)\n",
    "    return p_soft_mat, p_hard_mat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start to calculate p for different n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ns is list of n_train\n",
    "ns = np.array([1300000, 1000000, 700000, 400000, 200000, 50000])\n",
    "repeats = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in ns:\n",
    "    ps_L, ps_L_thres = get_p_from_10_model(n, 'Res_Net', repeats)\n",
    "    np.save('./Res_Net/%d_soft.npy'%n, ps_L)\n",
    "    np.save('./Res_Net/%d_hard.npy'%n, ps_L_thres)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:16<00:00, 76.88s/it]\n"
     ]
    }
   ],
   "source": [
    "for n in ns:\n",
    "    ps_L, ps_L_thres = get_p_from_10_model(n, 'Mix', repeats)\n",
    "    np.save('./Mix/%d_soft.npy'%n, ps_L)\n",
    "    np.save('./Mix/%d_hard.npy'%n, ps_L_thres)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:25<00:00, 25.91s/it]\n"
     ]
    }
   ],
   "source": [
    "for n in ns:\n",
    "    ps_B, ps_B_thres = get_p_from_10_model(n, 'LBI', repeats)\n",
    "    np.save('./LBI/%d_soft.npy'%n, ps_B)\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:59<00:00, 59.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for n in ns:\n",
    "    ps_G, ps_G_thres = get_p_from_10_model(n, 'Fea_Gau', repeats)\n",
    "    np.save('./Fea_Gau/%d_soft.npy'%n, ps_G)\n",
    "    np.save('./Fea_Gau/%d_hard.npy'%n, ps_G_thres)\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.59s/it]\n"
     ]
    }
   ],
   "source": [
    "for n in ns:\n",
    "    ps_O, ps_O_thres = get_p_from_10_model(n, 'Gaussian', repeats)\n",
    "    np.save('./Gaussian/%d_soft.npy'%n, ps_O)\n",
    "    np.save('./Gaussian/%d_hard.npy'%n, ps_O_thres)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in ns:\n",
    "    ps_S, ps_S_thres = get_p_from_10_model(n, 'Scheffe', repeats)\n",
    "    np.save('./Scheffe/%d_soft.npy'%n, ps_S)\n",
    "    np.save('./Scheffe/%d_hard.npy'%n, ps_S_thres)\n",
    "    _, ps_S_thres_05 = get_p_from_10_model(n, 'Scheffe', repeats, force_thres=0.5)\n",
    "    np.save('./Scheffe/%d_05.npy'%n, ps_S_thres_05)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3398c4b5aa1e55195b0bb96b4f8fc5c3f4a0ffb5794362f58b6653d525fb08f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
